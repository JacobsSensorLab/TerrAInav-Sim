{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-06 14:22:53.036656: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-06 14:22:54.022368: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/sdjkhosh/.local/lib/python3.10/site-packages/cv2/../../lib64:/usr/local/cuda/lib64:\n",
      "2025-01-06 14:22:54.022466: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/sdjkhosh/.local/lib/python3.10/site-packages/cv2/../../lib64:/usr/local/cuda/lib64:\n",
      "2025-01-06 14:22:54.022477: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# @title Import Libraries\n",
    "import sys\n",
    "import glob, os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopy.distance\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from skimage import exposure\n",
    "from skimage import feature\n",
    "import skimage.measure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sdjkhosh/Projects/SkyAI-Sim\n",
      "README.md  \u001b[0m\u001b[01;34mdataset\u001b[0m/  requirements.txt  \u001b[01;34msrc\u001b[0m/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: SkyAI Sim Project [-h] [--coords COORDS] [--fov FOV]\n",
      "                         [--aspect_ratio ASPECT_RATIO [ASPECT_RATIO ...]]\n",
      "                         [--utm UTM] [--map_type {satellite,roadmap,terrain}]\n",
      "                         [--dataset {SkyAI,VBN}] [--data_dir DATA_DIR]\n",
      "                         [--vmargin VMARGIN]\n",
      "                         [--img_size IMG_SIZE [IMG_SIZE ...]]\n",
      "                         [--overlap OVERLAP] [--batch_size BATCH_SIZE]\n",
      "                         [--seed SEED]\n",
      "SkyAI Sim Project: error: argument --fov: invalid float value: '/home/sdjkhosh/.local/share/jupyter/runtime/kernel-v35aad76d9681d819be17f09a29072c876f13a57c8.json'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Namespace(coords=[35.19, -89.94, 35.11, -89.8, 120.0], fov=78.8, aspect_ratio=[4, 3], utm='EPSG:32616', map_type='roadmap', dataset='SkyAI', data_dir='/home/sdjkhosh/Datasets/Memphis/', vmargin=20, img_size=[400, 400, 3], overlap=0.6, batch_size=8, seed=2024)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup paths and import local libraries\n",
    "%cd ../../\n",
    "%ls\n",
    "\n",
    "prj_path = Path('SkyAI-Sim')\n",
    "sys.path.insert(0, str(prj_path))\n",
    "from src.utils import img_helper\n",
    "from src.utils.io_helper import str_to_floats\n",
    "from src.utils import consts\n",
    "from src.data.skyai import SkyAI\n",
    "\n",
    "args = consts.ARGS\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(coords=[35.19, -89.94, 35.11, -89.8, 120.0], fov=78.8, aspect_ratio=[4, 3], utm='EPSG:32616', map_type='roadmap', dataset='SkyAI', data_dir='/home/sdjkhosh/Datasets/Memphis/', vmargin=20, img_size=[400, 400, 3], overlap=0.6, batch_size=8, seed=2024)\n",
      "Checking folder:\n",
      "\t /home/sdjkhosh/Datasets/Memphis/roadmap_0.6 Folder Exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-06 14:23:01.205376: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2025-01-06 14:23:01.205436: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: c2-parisa\n",
      "2025-01-06 14:23:01.205453: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: c2-parisa\n",
      "2025-01-06 14:23:01.205584: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 510.54.0\n",
      "2025-01-06 14:23:01.205635: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 510.54.0\n",
      "2025-01-06 14:23:01.205643: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 510.54.0\n",
      "2025-01-06 14:23:01.206319: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "aerial_data = SkyAI(\n",
    "        args=args,\n",
    "        map_type='roadmap',\n",
    "        data_dir=args.data_dir,\n",
    "        overlap=args.overlap\n",
    "        )\n",
    "# aerial_data.config(download_raster=False)\n",
    "aerial_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aerial_imgs_path = glob.glob(os.path.join(aerial_data.data_dir / 'images', \"*.jpg\"))\n",
    "aerial_imgs_path.sort()\n",
    "print(len(aerial_imgs_path))\n",
    "aerial_imgs, aerial_titles = img_helper.choose_random_images(nx*ny,\n",
    "                                                            aerial_imgs_path,\n",
    "                                                            output_dir=aerial_data.data_dir / 'random_sample',\n",
    "                                                            obj=aerial_data,\n",
    "                                                            seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.measure\n",
    "entropys = [skimage.measure.shannon_entropy(img) for img in aerial_imgs]\n",
    "\n",
    "img_helper.plot_multy(aerial_imgs, aerial_data.data_dir /'entropies', nx, ny, entropys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "road_n = [cv2.normalize(img, None, alpha = 0, beta = 255,\n",
    "                       norm_type = cv2.NORM_MINMAX,\n",
    "                       dtype = cv2.CV_32F).astype('uint8') for img in aerial_imgs]\n",
    "road_gray = [cv2.cvtColor(real_img, cv2.COLOR_BGR2GRAY) for real_img in road_n]\n",
    "img_helper.plot_multy(road_gray, '../Gray Scale \\nRoadmap Images', nx, ny, aerial_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "road_eq = [cv2.equalizeHist(img) for img in road_gray]\n",
    "img_helper.plot_multy(road_eq, '../Equalized Gray Scale \\nRoadmap Images', nx, ny, aerial_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# equalize each color channel\n",
    "eq_color = [cv2.merge([cv2.equalizeHist(channel) for channel in cv2.split(img)]) for img in road_n]\n",
    "img_helper.plot_multy(eq_color, '../Equalized Color \\nRoadmap Images', nx, ny, aerial_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skyai-sim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
